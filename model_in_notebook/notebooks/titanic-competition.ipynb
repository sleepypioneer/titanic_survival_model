{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Building a survival model for the Titanic Kaggle competition"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-1-a1836312946b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mseaborn\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0msns\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mmatplotlib\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpyplot\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mget_ipython\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrun_line_magic\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'matplotlib'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'inline'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'seaborn'"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Importing the data"
   ]
  },
  {
   "metadata": {
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# Read data out into train and test dataframes\n",
    "train = pd.read_csv('/kaggle/input/titanic/train.csv', index_col='PassengerId')\n",
    "test = pd.read_csv('/kaggle/input/titanic/test.csv', index_col='PassengerId')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# Print out the top 5 rows of the training data\n",
    "train.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# Print out the top 5 rows of the test data\n",
    "test.head()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# look at the datatypes and null values for the training data\n",
    "train.info()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# Look at the columns present in both training and test data\n",
    "print('Train data columns: ', train.columns)\n",
    "print('Test data columns: ', test.columns)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "# Look at what data is categorical data\n",
    "s = (train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "print('Categorical columns: ', object_cols)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Exploring relationships in the data"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "sns.lmplot(x='Age', y='Fare', hue='Survived', data=train)\n",
    "plt.title('Realtionship between age and fare split by survival on the Titanic')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We can a positive coloration for those who surrived between thier age and the fare they paid. Showing that older passengers tended to pay more for their fare. We  However for those who did not surrive while still positive this relationship is less evident."
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "sns.lmplot(x='Parch', y='SibSp', hue='Survived', data=train)\n",
    "plt.title('Realtionship between having siblings or spouse with you and being a parent or child split by survival on the Titanic')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In both those who surrived and those who did not there is a positive correlation between a passenger having more siblings or spouse and being a parent or child, perhaps indicating the amount of families travelling aboard."
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "sns.lmplot(x='Age', y='SibSp', hue='Survived', data=train)\n",
    "plt.title('Realtionship between age and having a sibling or spouse split by survival on the Titanic')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Here regardless of your surrival the older you were the less likely you had a sibling or spouse with you."
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "sex_grouped_by_survival = train.groupby(['Survived']).Sex.value_counts().sort_index()\n",
    "sex_grouped_by_survival"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "survived = plt.bar(range(len(sex_grouped_by_survival[0])), sex_grouped_by_survival[0], color='purple')\n",
    "died = plt.bar(range(len(sex_grouped_by_survival[1])), sex_grouped_by_survival[1], color='yellow', bottom=sex_grouped_by_survival[0])\n",
    "plt.legend([survived, died], ['Died', 'Survived'])\n",
    "labels = ['Female', 'Male', ]\n",
    "plt.xticks(range(len(sex_grouped_by_survival[1])), labels)\n",
    "plt.ylabel('Number of passengers')\n",
    "plt.title('Realtionship between a passengers Sex and survival on the Titanic')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "Here we see that more female passengers surrived in this data in comparison to male passengers. We can also conclude that in general the ratio of male passengers who survived compared to the total amount of male passengers aboard the titanic is very low where as a higher percentage of the female passengers survived."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Looking at the relationship class and sex has on survival on the Titanic"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "print(train.groupby(['Sex', 'Pclass']).mean()['Survived'])\n",
    "print(train.groupby(['Sex', 'Pclass']).std()['Survived'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "train['Survival'] = train.Survived.map(lambda t: 'Survived' if t == 1 else 'Died')\n",
    "train['Class'] = train.Pclass.map(lambda t: '1st class' if t == 1 else ('2nd class' if t == 2 else '3rd class'))\n",
    "\n",
    "(train\n",
    ".groupby(['Survival', 'Class', 'Sex'])\n",
    ".Class\n",
    ".count()\n",
    ".plot(kind='bar')\n",
    ")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The largest group from the Titanic by far was 3rd class males who died by quite a gap. We can also see that females in 1st and 2nd class more often survived than died but females from 3rd class appear to be split in half between those which survived and those who did not."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Female Passengers statistics (for the training data)"
   ]
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": [
    "#Number of Female passengers\n",
    "female_passengers = train.loc[train['Sex'] == 'female']\n",
    "print('Number of female passengers in training data: ', len(female_passengers))\n",
    "\n",
    "# Number of female passengers under 18\n",
    "female_passengers_under_18 = female_passengers.loc[female_passengers['Age'] < 18]\n",
    "print('Number of female passengers under 18 in training data: ', len(female_passengers_under_18))\n",
    "\n",
    "# Number of female passengers over 60\n",
    "female_passengers_over_60 = female_passengers.loc[female_passengers['Age'] > 60]\n",
    "print('Number of female passengers over 60 in training data: ', len(female_passengers_over_60))\n",
    "\n",
    "# Number of female passengers traveling with a parent or child\n",
    "female_passengers_parch = female_passengers.loc[female_passengers['Parch'] >= 1]\n",
    "print('Number of female passengers traveling with a parent or child in training data: ', len(female_passengers_parch))\n",
    "\n",
    "# Number of female passengers traveling with a sibling or spouse\n",
    "female_passengers_with_sibsp = female_passengers.loc[female_passengers['SibSp'] >= 1]\n",
    "print('Number of female passengers traveling with a sibling or spouse in training data: ', len(female_passengers_with_sibsp))\n",
    "\n",
    "# Number of female passengers who survived\n",
    "female_passengers_that_survived = female_passengers.loc[female_passengers['Survived'] == 1]\n",
    "print('Number of female passengers that survived in training data: ', len(female_passengers_that_survived))\n",
    "\n",
    "# Percentage of female passengers that survived f'{x:.0%}'\n",
    "print('Precentage of female passengers that survived in training data: ', f'{len(female_passengers_that_survived)/len(female_passengers)*100:.1f}%')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The difference between class and surrival is not as large as I would have expected. I wonder if this graph is somewhat decieving as it's hard to read what was the truth for those in 3rd class. Did none surrive? It's hard to say. Only that the majority of surrivers were in the first and second class."
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Extract surname into separate column\ntrain['Surname'] = train['Name'].map(lambda x: x.split(',')[0])\nprint(train['Surname'][0:5])",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Extract title into separate column\ntrain['Title'] = train['Name'].map(lambda x: x.split(',')[1].split('.')[0].strip())\ntrain['Title'] = train['Title'].map(lambda x: 'Countess' if x == 'the Countess' else x)\n# Mlle == Mademoiselle\n# Don ==  A head, tutor, or fellow at a college of Oxford or Cambridge. Or title for males in spanish speaking areas\nfor title in train['Title'].unique():\n    print(title, train.loc[(train['Title'] == title)].size)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "plt.title('Title distribution of those who survived on the Titanic')\n(train[train.Survived == 1]\n.groupby(['Title'])\n.Title\n.count()\n.plot(kind='bar')\n)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "plt.title('Title distribution of those who died on the Titanic')\n(train[train.Survived == 0]\n.groupby(['Title'])\n.Title\n.count()\n.plot(kind='bar')\n)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "It's hard to say if there is a correlation between title and survival. We can see see that the largest group of those who died held the title Mr. This relationship could be indirectly, for example master is a title for young men and more children surrived than adults."
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Extract first name into separate column\ntrain['First_names'] = train['Name'].map(lambda x: x.split('.')[1].split('(')[0].strip())\nprint(train['First_names'][0:5])",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "number_of_passengers_named_john = len(train.loc[train['First_names'] == 'John'])",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "(train\n.groupby(['Survival', 'First_names'])\n.First_names\n.count()\n.sort_values(ascending=False)\n[:10]\n)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "While it remains unlikely someone's first name would play a role in their survival on the Titanic interesting all of the passengers in the training data called John died. This isn't statistically so suprising as they were most likely male passengers and we've already discovered male passengers were predominently in the group which died. It may point to patterns in the names given to different classes if indeed such a thing existed."
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Extract alternative name into separate column\ntrain['Alternative_name'] = train['Name'].map(lambda x: x.split('(')[1].split(')')[0] if '(' in x else '')\nprint(train['Alternative_name'][0:5])",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Extract alternative surname (most likely maiden name) into separate column\ntrain['Alternative_surname'] = train['Alternative_name'].map(lambda alt_name: '' if alt_name == '' else alt_name.split()[-1])\nfor alt_surname in train['Alternative_surname'].unique():\n    print(alt_surname, train.loc[(train['Alternative_surname'] == alt_surname)].Alternative_surname.count())",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Look at how many values there are for cabin\nfor cabin in train['Cabin'].unique():\n    print(cabin, train.loc[(train['Cabin'] == cabin)].size)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Extract which deck a passager had their cabin based on the Cabin number\ntrain['Deck']= train['Cabin'].map(lambda x: 'Unknown' if str(x) == 'nan' else str(x)[0])",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "plt.title('Realtionship between Deck and survival on the Titanic')\n(train[train.Deck != 'Unknown']\n.groupby(['Survival', 'Deck'])\n.Deck\n.count()\n.plot(kind='bar')\n)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "This maybe gives some insight to how decks were labelled on the titanic. We would ideally want to look at a map to see where the decks were to read more into these results. Did decks divide classes, did they also divide workers from passengers? Did all decks have the same amount of occupants? However it seems surrival seemed more likely if you were on deck E, D, B."
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "deck_data = train[train.Deck != 'Unknown'].groupby(['Deck', 'Survival']).Deck.count() # remove unknowns as they skew the data\ndeck_data\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "deck_survival_ratio = pd.Series()\n\nfor deck in train.Deck:\n    survivors = train[(train.Deck == deck) & (train.Survived == 1)].Deck.count()\n    total_deck_passengers = train[train.Deck == deck].Deck.count()\n    ratio = (survivors/total_deck_passengers)*100\n    deck_survival_ratio[deck] = ratio\n\nplt.title('Ratio of survival per deck on the Titanic')\ndeck_survival_ratio.sort_index().plot(kind='bar')",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Extract the ticket type (assuming potentially where they bought the ticket) from the ticket value\ntrain['Ticket_type'] = train['Ticket'].map(lambda x: x.split()[0] if any(c.isalpha() for c in x.split()[0]) else 'Unknown')\nprint(train['Ticket_type'].unique())\nprint(train['Ticket_type'].unique().size)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "plt.figure(figsize=(16,10))\nplt.title('Realtionship between Ticket type and survival on the Titanic')\n(train[train.Ticket_type != 'Unknown']\n.groupby(['Survival', 'Ticket_type'])\n.Ticket_type\n.count()\n.plot(kind='bar')\n)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "raw",
   "source": "Certain tickets seems to offer a better chance of surrival, was this because those tickets were only for a certain deck or class?"
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Look at how many values there are for ticket tzpe\nfor ticket in train['Ticket_type'].unique():\n    print(ticket, train.loc[(train['Ticket_type'] == ticket)].Ticket_type.count())",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Put feature columns into X_train dataframe\n# base_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Surname', 'Title', 'Alternative_surname', 'Deck', 'Ticket_type']\nbase_features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'Title', 'Deck', 'Ticket_type']\nX_train = train[base_features].copy()\nX_train.index = train.index\n# Put survival value into y\ny = train['Survived']\n\nprint(y.head())\nX_train.head()",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Look at what data is categorical data\ns = (X_train.dtypes == 'object')\nobject_cols = list(s[s].index)\nprint(object_cols)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Update the Embarked column to replace nan values with unknown\nX_train['Embarked'] = X_train['Embarked'].fillna('unknown')\n\nprint(X_train['Embarked'].unique())",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Update the Age column to replace nan values with the mean value\nX_train['Age'].fillna(X_train['Age'].mean(), inplace=True)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Check cardinality of categorical variables\nobject_nunique = list(map(lambda col: X_train[col].nunique(), object_cols))\nd = dict(zip(object_cols, object_nunique))\n# Print in ascending order\nsorted(d.items(), key=lambda x: x[1])\n\n# We can conclude that for those with low cardinality we can use one-hot encoding and for the time being I am dropping those with high cardinality",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Assign categorical data columns to low or high cardinality lists\nlow_cardinality = ['Deck', 'Title', 'Sex', 'Embarked', 'Ticket_type']\n# high_cardinality  = ['Ticket_type', 'Alternative_surname', 'Surname']",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# from sklearn.preprocessing import LabelEncoder\n# label_encoder = LabelEncoder()\n# for col in high_cardinality:\n#     X_train[col] = label_encoder.fit_transform(X_train[col])\n\nX_train.head()\nX_train.info()",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "from sklearn.preprocessing import OneHotEncoder\nOH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\nOH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[low_cardinality]))\nprint('OH_cols_train: ', OH_cols_train.columns.tolist(), ' shape ', OH_cols_train.shape)\nnon_oh_encoded = X_train.drop(low_cardinality, axis=1)\nOH_cols_train.index = X_train.index\nprint('non_oh_encoded: ', non_oh_encoded.columns.tolist(), ' shape ', non_oh_encoded.shape)\nOH_X_train = pd.concat([non_oh_encoded, OH_cols_train], axis=1)\nOH_X_train.index = X_train.index\nprint('OH_X_train: ', OH_X_train.columns.tolist(), ' shape ', OH_X_train.shape)\nOH_X_train.columns",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# update column names to string type\nOH_X_train.columns = OH_X_train.columns.astype(str)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split\ntrain_X, val_X, train_y, val_y = train_test_split(OH_X_train, y, random_state = 0)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "val_X.dropna(axis=0, how='any', inplace=True)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "print(train_X.columns)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "from sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier(random_state=0)\nrf_model.fit(train_X, train_y.values.ravel())",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "predictions = rf_model.predict(val_X)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "print(predictions[0:5])\nprint(val_y[0:5])\nprint(f'Accuracy: {rf_model.score(val_X, val_y):.2f}%')",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(rf_model, random_state=1).fit(val_X, val_y)\n\neli5.show_weights(perm, feature_names=val_X.columns.tolist())",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Permutation importance of features"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Here it appears that Pclass, Fare, Age and sibsp have relatively high importance as features. One or two of the one-hot-encoded values also appear to have a high importance. With the current one-hot-encoder I unfortunately cannot tell which one these refers to."
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "important_features = ['Pclass', 'Fare', 'Age','SibSp']",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "from sklearn.model_selection import train_test_split\ntrain_reduced_features_X, val_reduced_features_X, train_reduced_features_y, val_reduced_features_y = train_test_split(OH_X_train[important_features], y, random_state = 0)\nval_X.dropna(axis=0, how='any', inplace=True)\n\nfrom sklearn.ensemble import RandomForestClassifier\nrf_reduced_features_model = RandomForestClassifier(random_state=0)\nrf_reduced_features_model.fit(train_reduced_features_X, train_reduced_features_y.values.ravel())\n\npredictions = rf_reduced_features_model.predict(val_reduced_features_X)\n\nprint('Predictions: ', predictions[0:5])\nprint('Y Values: ', val_reduced_features_y[0:5])\nprint(f'Accuracy: {rf_reduced_features_model.score(val_reduced_features_X, val_reduced_features_y):.2f}%')",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see here our accuracy has actually been reduced by using only the features that the permutation said were important."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Partial dependence plots"
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "from pdpbox import pdp, get_dataset, info_plots\n\n\nfor feature_name in important_features:\n    pdp_goals = pdp.pdp_isolate(model=rf_model, dataset=val_X, model_features=val_X.columns.tolist(), feature=feature_name)\n    pdp.pdp_plot(pdp_goals, feature_name)\n    plt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2D Partial Dependance Plots"
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "inter1 = pdp.pdp_interact(model=rf_model, dataset=val_X, model_features=val_X.columns.tolist(), features=important_features)\npdp.pdp_interact_plot(pdp_interact_out=inter1, feature_names=val_X.columns.tolist(), plot_type='contour')\nplt.show()",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### SHAP Values\nbreak down a prediction to show the impact of each feature."
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "row_to_show = 5\ndata_for_prediction = val_X.iloc[row_to_show]  # use 1 row of data here. Could use multiple rows if desired\ndata_for_prediction_array = data_for_prediction.values.reshape(1, -1)\n\n\nrf_model.predict_proba(data_for_prediction_array)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "import shap\nexplainer = shap.TreeExplainer(rf_model)\nshap_values = explainer.shap_values(data_for_prediction)\nshap.initjs()\ndata_for_prediction = val_X.iloc[1]\nshap.force_plot(explainer.expected_value[1], shap_values[1], data_for_prediction) # looking at values for those that surrived\n#  Shap values show how much a given feature changed our prediction (compared to if we made that prediction at some baseline value of that feature).",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# Create object that can calculate shap values\nexplainer = shap.TreeExplainer(rf_model)\n\n# calculate shap values. This is what we will plot.\n# Calculate shap_values for all of val_X rather than a single row, to have more data for plot.\nshap_values = explainer.shap_values(val_X)\n\n# Make plot. Index of [1] is explained in text below.\nshap.summary_plot(shap_values[1], val_X)",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {
    "trusted": true
   },
   "cell_type": "code",
   "source": "# # Create object that can calculate shap values\n# explainer = shap.TreeExplainer(my_model)\n\n# # calculate shap values. This is what we will plot.\n# shap_values = explainer.shap_values(X)\n\n# make plot.\nshap.dependence_plot('Age', shap_values[1], val_X, interaction_index=\"Pclass\")",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}